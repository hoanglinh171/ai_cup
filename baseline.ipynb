{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train set: Use data from 7am - 17pm in train set\n",
    "2. Test set: To evaluate, only evaluate prediction from 9am - 17pm \n",
    "3. Impute missing for all data by linear interpolation, fill forward and backward\n",
    "4. Scale min max, fit train set\n",
    "5. Train features to predict their futures by LSTM\n",
    "6. Train features with response to predict response by Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(data):\n",
    "  \"\"\"\n",
    "  data: DataFrame\n",
    "  \"\"\"\n",
    "  \n",
    "  features = data.columns\n",
    "  for feature in features:\n",
    "    data[feature] = data[feature].interpolate(method='nearest', limit_direction='both')\n",
    "    data[feature] = data[feature].ffill()\n",
    "    data[feature] = data[feature].bfill()\n",
    "  \n",
    "  return data\n",
    "\n",
    "\n",
    "def scale_min_max(fit_data):\n",
    "  \"\"\"\n",
    "  train_set, test_set: numpy array\n",
    "  \"\"\"\n",
    "  minmax_scaler = MinMaxScaler().fit(fit_data)\n",
    "  data_scaled = minmax_scaler.transform(fit_data)\n",
    "  # val_set_scaled = minmax_scaler.transform(val_set)\n",
    "  # test_set_scaled = minmax_scaler.transform(test_set)\n",
    "\n",
    "  return data_scaled, minmax_scaler\n",
    "\n",
    "\n",
    "def window_data(data, look_back_num):\n",
    "  \"\"\"\n",
    "  data: numpy array\n",
    "  \"\"\"\n",
    "  X_train = []\n",
    "  y_train = []\n",
    "\n",
    "  # # input X, each look_back_num points is corresponding to 1 y (y dim is 5)\n",
    "  for i in range(look_back_num, data.shape[0]):\n",
    "    X_train.append(data[i-look_back_num:i, :])\n",
    "    y_train.append(data[i, :])\n",
    "\n",
    "  X_train = np.array(X_train)\n",
    "  y_train = np.array(y_train)\n",
    "\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], data.shape[1]))  # num obs * time sequence length * num features\n",
    "\n",
    "  return X_train, y_train\n",
    "\n",
    "\n",
    "# Modelling\n",
    "\n",
    "def lstm_model(X_train, y_train, epochs, batch_size):\n",
    "  regressor = Sequential()\n",
    "  regressor.add(LSTM(units = 128, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))  # each input is time sequence length * num features\n",
    "  regressor.add(LSTM(units = 64))\n",
    "  regressor.add(Dropout(0.2))\n",
    "\n",
    "  # output layer\n",
    "  regressor.add(Dense(units=y_train.shape[1]))\n",
    "  regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "  # regressor.summary()\n",
    "  history = regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, verbose=False)\n",
    "\n",
    "  return regressor, history\n",
    "\n",
    "def train_model(loc, look_back_num, epochs, batch_size):\n",
    "  ## LSTM\n",
    "\n",
    "  train_file = os.path.join(os.getcwd(), \"data/avg_data_10min_wh/loc_{i}/fold_4/train.csv\".format(i=loc))\n",
    "  train_set = pd.read_csv(train_file, encoding='utf-8')\n",
    "\n",
    "  features = ['WindSpeed(m/s)','Pressure(hpa)','Temperature(째C)','Humidity(%)','Sunlight(Lux)', 'Power(mW)']\n",
    "  # features = ['Pressure(hpa)','Temperature(째C)','Humidity(%)','Sunlight(Lux)', 'Power(mW)']\n",
    "  X_features = features[:-1]\n",
    "  train_imputed = impute_missing(train_set[features])\n",
    "  # print(np.sum(np.isnan(train_imputed)))\n",
    "  # train_imputed = train_set[features].dropna()\n",
    "  train_scaled, minmax_scaler = scale_min_max(train_imputed[X_features])\n",
    "  X_train, X_train_later = window_data(train_scaled, look_back_num)\n",
    "  regressor, history = lstm_model(X_train, X_train_later, epochs, batch_size)\n",
    "\n",
    "  ## Regression\n",
    "\n",
    "  y_train = np.log(train_imputed[['Power(mW)']])\n",
    "  lin_reg = LinearRegression(n_jobs=5)\n",
    "  lin_reg.fit(train_scaled, y_train)\n",
    "\n",
    "  return minmax_scaler, regressor, history, lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(model, forecast_num, look_back_num, X_test):\n",
    "  # Only apply for look_back_num = 12 and forecast_num = 48\n",
    "  predictions = []\n",
    "  \n",
    "  i = 0\n",
    "  complete_day = (len(X_test) + look_back_num) // (forecast_num + look_back_num)\n",
    "  interval_left = (len(X_test) + look_back_num) % (forecast_num + look_back_num)\n",
    "  if (interval_left == 0): \n",
    "    count = forecast_num\n",
    "  else:\n",
    "    count = interval_left\n",
    "    \n",
    "  while i < len(X_test) - count: \n",
    "    if i > forecast_num:\n",
    "      i += look_back_num\n",
    "      \n",
    "    input = X_test[i].reshape(1, X_test.shape[1], X_test.shape[2])\n",
    "    for _ in range(forecast_num):\n",
    "      next_pred = model.predict(input, verbose=False)\n",
    "      predictions.append(next_pred[0])\n",
    "      input = np.append(input[:, 1:, :], [[next_pred[0]]], axis=1)\n",
    "    i += forecast_num\n",
    "\n",
    "  if (interval_left >= look_back_num):\n",
    "    predictions = np.array(predictions)[:(complete_day * forecast_num) + interval_left - look_back_num]\n",
    "  else:\n",
    "    predictions = np.array(predictions)[:(complete_day * forecast_num)]\n",
    "\n",
    "  return np.array(predictions)\n",
    "\n",
    "\n",
    "def predict_power(loc, look_back_num, forecast_num, lstm_regressor, lin_reg, minmax_scaler):\n",
    "  test_file = os.path.join(os.getcwd(), \"data/avg_data_10min_wh/loc_{i}/fold_4/test.csv\".format(i=loc))\n",
    "  test_set = pd.read_csv(test_file, encoding='utf-8')\n",
    "  test_set['is_missing'] = np.where(test_set['Power(mW)'].isna(), 1, 0)\n",
    "\n",
    "  features = ['WindSpeed(m/s)','Pressure(hpa)','Temperature(째C)','Humidity(%)','Sunlight(Lux)', 'Power(mW)']\n",
    "  # features = ['Pressure(hpa)','Temperature(째C)','Humidity(%)','Sunlight(Lux)', 'Power(mW)']\n",
    "  X_features = features[:-1]\n",
    "  test_imputed = impute_missing(test_set[features])\n",
    "  test_scaled = minmax_scaler.transform(test_imputed[X_features])\n",
    "  X_test, _ = window_data(test_scaled, look_back_num)\n",
    "  X_test_pred = lstm_predict(lstm_regressor, forecast_num, look_back_num, X_test)\n",
    "\n",
    "  X_test_true = pd.concat([test_set[['DateTime', 'is_missing']], test_imputed], axis=1)\n",
    "  hour_dt = pd.to_datetime(X_test_true[\"DateTime\"]).dt.time\n",
    "  X_test_true = X_test_true[(hour_dt >= pd.to_datetime(\"09:00\").time()) & \n",
    "                            (hour_dt < pd.to_datetime(\"17:00\").time())]\n",
    "  y_test = X_test_true['Power(mW)']\n",
    "  y_pred = lin_reg.predict(X_test_pred).reshape(y_test.shape[0])\n",
    "  y_pred = np.exp(y_pred)\n",
    "\n",
    "  return X_test_true, X_test_pred, y_pred, y_test, X_test_true[['DateTime', 'is_missing']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "MAE of location 1:  491.0656634292075\n",
      "2\n",
      "MAE of location 2:  442.7963339568124\n",
      "3\n",
      "MAE of location 3:  645.9870249514242\n",
      "4\n",
      "MAE of location 4:  624.6627430019973\n",
      "5\n",
      "MAE of location 5:  688.8044507132197\n",
      "6\n",
      "MAE of location 6:  702.6596720292455\n",
      "7\n",
      "MAE of location 7:  924.8281714017742\n",
      "8\n",
      "MAE of location 8:  124.71365248775092\n",
      "9\n",
      "MAE of location 9:  221.80564622744953\n",
      "10\n",
      "MAE of location 10:  337.35282728359067\n",
      "11\n",
      "MAE of location 11:  13.758789101843034\n",
      "12\n",
      "MAE of location 12:  514.2359599503327\n",
      "13\n",
      "MAE of location 13:  556.3006167470363\n",
      "14\n",
      "MAE of location 14:  441.7676825279338\n",
      "15\n",
      "MAE of location 15:  505.0203309729414\n",
      "16\n",
      "MAE of location 16:  613.643311563426\n",
      "17\n",
      "MAE of location 17:  477.50412412535434\n"
     ]
    }
   ],
   "source": [
    "location_lst = range(1, 18, 1)\n",
    "look_back_num = 12\n",
    "forecast_num = 48\n",
    "\n",
    "all_predictions = pd.DataFrame(columns = [\"datetime\", \"location\", \"y_test\", \"y_pred\"])\n",
    "for loc in location_lst:\n",
    "    print(loc)\n",
    "    minmax_scaler, regressor, history, lin_reg = train_model(loc, look_back_num=look_back_num, epochs=300, batch_size=512)\n",
    "    X_test_true, X_test_pred, y_pred, y_test, date_miss = predict_power(loc, look_back_num=look_back_num, \n",
    "                                                             forecast_num=forecast_num, lstm_regressor=regressor, \n",
    "                                                             lin_reg=lin_reg, minmax_scaler=minmax_scaler)\n",
    "    df = pd.DataFrame(columns = [\"datetime\", \"location\", \"y_test\", \"y_pred\", \"is_missing\"])\n",
    "    df[\"datetime\"] = date_miss['DateTime']\n",
    "    df[\"is_missing\"] = date_miss['is_missing']\n",
    "    df[\"location\"] = loc\n",
    "    df[\"y_test\"] = y_test\n",
    "    df[\"y_pred\"] = y_pred\n",
    "    print(\"MAE of location {i}: \".format(i=loc), np.mean(np.abs(df['y_test'] - df['y_pred'])))\n",
    "\n",
    "    all_predictions = pd.concat([all_predictions, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of location 10:  858.1438707649787\n"
     ]
    }
   ],
   "source": [
    "## Retrain 10 because it looks weird\n",
    "\n",
    "minmax_scaler, regressor, history, lin_reg = train_model(10, look_back_num=look_back_num, epochs=500, batch_size=512)\n",
    "X_test_true, X_test_pred, y_pred, y_test, date_miss = predict_power(10, look_back_num=look_back_num, \n",
    "                                                            forecast_num=forecast_num, lstm_regressor=regressor, \n",
    "                                                            lin_reg=lin_reg, minmax_scaler=minmax_scaler)\n",
    "\n",
    "df = pd.DataFrame(columns = [\"datetime\", \"location\", \"y_test\", \"y_pred\", \"is_missing\"])\n",
    "df[\"datetime\"] = date_miss['DateTime']\n",
    "df[\"is_missing\"] = date_miss['is_missing']\n",
    "df[\"location\"] = loc\n",
    "df[\"y_test\"] = y_test\n",
    "df[\"y_pred\"] = y_pred\n",
    "print(\"MAE of location {i}: \".format(i=10), np.mean(np.abs(df['y_test'] - df['y_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.loc[all_predictions['location'] == 10, :] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526.1322911115961"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_missing = all_predictions[all_predictions['is_missing'] == 0]\n",
    "mae = np.mean(np.abs(no_missing['y_test'] - no_missing['y_pred']))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.to_csv(\"output/output_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (without windspeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "MAE of location 1:  2565.461643806146\n",
      "2\n",
      "MAE of location 2:  362.86356925642275\n",
      "3\n",
      "MAE of location 3:  1441.455912933955\n",
      "4\n",
      "MAE of location 4:  659.2662560568165\n",
      "5\n",
      "MAE of location 5:  748.7796853483253\n",
      "6\n",
      "MAE of location 6:  562.2626608133307\n",
      "7\n",
      "MAE of location 7:  966.483484117751\n",
      "8\n",
      "MAE of location 8:  161.8023780989333\n",
      "9\n",
      "MAE of location 9:  230.6848413639127\n",
      "10\n",
      "MAE of location 10:  1092.0922996320612\n",
      "11\n",
      "MAE of location 11:  15.014703090918925\n",
      "12\n",
      "MAE of location 12:  510.9939710950664\n",
      "13\n",
      "MAE of location 13:  531.0760744192472\n",
      "14\n",
      "MAE of location 14:  425.99017836995523\n",
      "15\n",
      "MAE of location 15:  553.1719322121623\n",
      "16\n",
      "MAE of location 16:  588.081290298157\n",
      "17\n",
      "MAE of location 17:  473.2310054823779\n"
     ]
    }
   ],
   "source": [
    "location_lst = range(1, 18, 1)\n",
    "look_back_num = 12\n",
    "forecast_num = 48\n",
    "\n",
    "all_predictions = pd.DataFrame(columns = [\"datetime\", \"location\", \"y_test\", \"y_pred\"])\n",
    "for loc in location_lst:\n",
    "    print(loc)\n",
    "    minmax_scaler, regressor, history, lin_reg = train_model(loc, look_back_num=look_back_num, epochs=500, batch_size=512)\n",
    "    X_test_true, X_test_pred, y_pred, y_test, date_miss = predict_power(loc, look_back_num=look_back_num, \n",
    "                                                             forecast_num=forecast_num, lstm_regressor=regressor, \n",
    "                                                             lin_reg=lin_reg, minmax_scaler=minmax_scaler)\n",
    "    df = pd.DataFrame(columns = [\"datetime\", \"location\", \"y_test\", \"y_pred\", \"is_missing\"])\n",
    "    df[\"datetime\"] = date_miss['DateTime']\n",
    "    df[\"is_missing\"] = date_miss['is_missing']\n",
    "    df[\"location\"] = loc\n",
    "    df[\"y_test\"] = y_test\n",
    "    df[\"y_pred\"] = y_pred\n",
    "    print(\"MAE of location {i}: \".format(i=loc), np.mean(np.abs(df['y_test'] - df['y_pred'])))\n",
    "\n",
    "    all_predictions = pd.concat([all_predictions, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764.8591096328307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_missing = all_predictions[all_predictions['is_missing'] == 0]\n",
    "mae = np.mean(np.abs(no_missing['y_test'] - no_missing['y_pred']))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.to_csv(\"output/output_baseline_no_wind.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
